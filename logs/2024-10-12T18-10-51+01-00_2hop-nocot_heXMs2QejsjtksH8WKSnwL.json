{
  "version": 2,
  "status": "error",
  "eval": {
    "run_id": "frkdHXg8rDCiPEQdL6EuiZ",
    "created": "2024-10-12T18:10:51+01:00",
    "task": "2hop_nocot",
    "task_id": "heXMs2QejsjtksH8WKSnwL",
    "task_version": 0,
    "task_attribs": {},
    "task_args": {},
    "dataset": {
      "samples": 10,
      "shuffled": true
    },
    "model": "together/meta-llama/Llama-3-8b-chat-hf",
    "model_base_url": "https://api.together.xyz/v1",
    "model_args": {},
    "config": {
      "max_samples": 25,
      "max_tasks": 25,
      "max_subprocesses": 25
    },
    "revision": {
      "type": "git",
      "origin": "ghp:tomekkorbak/latent_reasoning.git",
      "commit": "47bf777"
    },
    "packages": {
      "inspect_ai": "0.3.32"
    }
  },
  "plan": {
    "name": "plan",
    "steps": [
      {
        "solver": "system_message",
        "params": {
          "template": "Answer the following question directly and concisely, without any reasoning. There is always an answer. If the answer is ambiguous, use your best guess."
        }
      },
      {
        "solver": "generate",
        "params": {
          "cache": "CachePolicy"
        }
      }
    ],
    "config": {
      "temperature": 0.0
    }
  },
  "stats": {
    "started_at": "2024-10-12T18:10:51+01:00",
    "completed_at": "2024-10-12T18:10:51+01:00",
    "model_usage": {}
  },
  "error": {
    "message": "TypeError(\"'custom_grader' is not declared as an async callable.\")",
    "traceback": "Traceback (most recent call last):\n\n  File \"/Users/mikita/miniconda3/envs/latent/lib/python3.10/site-packages/inspect_ai/_eval/task/run.py\", line 260, in task_run\n    sample_results = await asyncio.gather(*sample_coroutines)\n\n  File \"/Users/mikita/miniconda3/envs/latent/lib/python3.10/site-packages/inspect_ai/_eval/task/run.py\", line 435, in task_run_sample\n    await scorer(state, Target(sample.target)) if scorer else None\n\n  File \"/Users/mikita/miniconda3/envs/latent/lib/python3.10/site-packages/inspect_ai/scorer/_scorer.py\", line 123, in scorer_wrapper\n    raise TypeError(\n\nTypeError: 'custom_grader' is not declared as an async callable.\n",
    "traceback_ansi": "\u001b[31m┌─\u001b[0m\u001b[31m────────────────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────────────────────────\u001b[0m\u001b[31m─┐\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/Users/mikita/miniconda3/envs/latent/lib/python3.10/site-packages/inspect_ai/_eval/task/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m260\u001b[0m in \u001b[92mtask_run\u001b[0m       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/Users/mikita/miniconda3/envs/latent/lib/python3.10/site-packages/inspect_ai/_eval/task/\u001b[0m\u001b[1;33mrun.py\u001b[0m:\u001b[94m435\u001b[0m in                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[92mtask_run_sample\u001b[0m                                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/Users/mikita/miniconda3/envs/latent/lib/python3.10/site-packages/inspect_ai/scorer/\u001b[0m\u001b[1;33m_scorer.py\u001b[0m:\u001b[94m123\u001b[0m in \u001b[92mscorer_wrapper\u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\u001b[0m\n\u001b[1;91mTypeError: \u001b[0m\u001b[32m'custom_grader'\u001b[0m is not declared as an async callable.\n"
  }
}